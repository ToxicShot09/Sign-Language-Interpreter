{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1b918a-f439-4643-8d9b-82d927479aea",
   "metadata": {},
   "source": [
    "# installing and importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df47af85-f2e1-440e-ad6d-6042475deb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: mediapipe in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.10.10)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (69.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.0.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (23.2.0)\n",
      "Requirement already satisfied: jax in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.25)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.9.0.80)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: rich in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\samee\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow scikit-learn opencv-python mediapipe matplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f88bc-980f-44be-8e58-af1d18b1fe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51462ad0-0168-4f5f-a4b5-e2b04bd36526",
   "metadata": {},
   "source": [
    "# keypoints using mp holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0271421-99dc-43ba-9ea0-489716985ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic      #holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils  #drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e1859d-d16f-4f6f-88f0-c65ddf83bec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  #bgr2rgb\n",
    "    image.flags.writeable = False                   #img is no longer writeable\n",
    "    results = model.process(image)                  #make prediction\n",
    "    image.flags.writeable = True                    #img is writeable again\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  #rgb2bgr\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02112046-8ebd-4f96-ab8d-505a38397c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)        #draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)        #draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)   #draw lefthand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)  #draw righthand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07be70aa-7951-4e4b-ae08-0a91ec74540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    #draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                             mp_drawing.DrawingSpec(color = (80,110,10), thickness = 1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color = (80,256,121), thickness = 1, circle_radius=1)\n",
    "                             )\n",
    "    #draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color = (80,22,10), thickness = 2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color = (80,44,121), thickness = 2, circle_radius=2)\n",
    "                             )        \n",
    "    #draw lefthand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color = (121,22,76), thickness = 2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color = (121,44,250), thickness = 2, circle_radius=2) \n",
    "                             )   \n",
    "    #draw righthand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color = (245,117,66), thickness = 2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color = (245,66,230), thickness = 2, circle_radius=2)\n",
    "                             )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4a3057-77ea-41ee-8321-5e76cfe07f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "#set mediapipe model\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        #read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #make detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "\n",
    "        #draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        #show feed\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        #break out of loop gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c381965f-16e8-408b-8cee-c7746fd0fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_landmarks(frame, results)\n",
    "# plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03545680-04c0-42e1-bac6-b20fad56d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(results.pose_landmarks.landmark)\n",
    "# len(results.right_hand_landmarks.landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa12e82-d4e7-4434-bdbe-8392ab03ae7c",
   "metadata": {},
   "source": [
    "# extract keypoint values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfab181-351f-4fcb-94ec-661b46131ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([face, pose, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "874ee7c3-61b5-49a8-8f5c-4fc67e0cc314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.39879298,  0.49629995, -0.01944808, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test = extract_keypoints(results)\n",
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcaff519-4d0a-4bcf-bfe5-4a24ac4dff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1662,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6164390e-2102-4760-b1b5-2b318d955040",
   "metadata": {},
   "source": [
    "# setup folders for collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d31f0a90-458e-4883-ab0c-e391de1afc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the absolute path for the data directory\n",
    "# DATA_PATH = \"MP_Data\"\n",
    "# # Check if the directory exists, if not, create it\n",
    "# if not os.path.exists(DATA_PATH):\n",
    "#     os.makedirs(DATA_PATH)\n",
    "# DATA_PATH = 'C:/Users/samee/OneDrive/Desktop/Sign_Language/MP_Data'\n",
    "\n",
    "# # print(\"Data path:\", DATA_PATH)\n",
    "\n",
    "# # Actions that we try to detect (manually added first)\n",
    "# actions = np.array(['hello', 'thanks', 'i love you'])\n",
    "\n",
    "# # Thirty videos worth of data\n",
    "# no_sequences = 30\n",
    "\n",
    "# # Videos are going to be 30 frames in length\n",
    "# sequence_length = 30\n",
    "\n",
    "# # Get the folders present in the MP_Data directory and sort them by creation time\n",
    "# folders = sorted([folder for folder in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, folder))],\n",
    "#                  key=lambda folder: os.path.getctime(os.path.join(DATA_PATH, folder)))\n",
    "\n",
    "# # Append the remaining actions to the actions array\n",
    "# for folder in folders:\n",
    "#     if folder not in actions:\n",
    "#         actions = np.append(actions, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aac42c2-4604-4f7e-922e-aef80affcec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for action in actions: \n",
    "#     dirmax = np.max(np.array(os.listdir(os.path.join(DATA_PATH, action))).astype(int))\n",
    "#     for sequence in range(1,no_sequences+1):\n",
    "#         try: \n",
    "#             os.makedirs(os.path.join(DATA_PATH, action, str(dirmax+sequence)))\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "# for action in actions:\n",
    "#     action_path = os.path.join(DATA_PATH, action)\n",
    "    \n",
    "#     # Check if the action directory exists\n",
    "#     if not os.path.exists(action_path):\n",
    "#         os.makedirs(action_path)\n",
    "\n",
    "#     # Get the list of directories (sequences) within the action directory\n",
    "#     sequence_dirs = [d for d in os.listdir(action_path) if os.path.isdir(os.path.join(action_path, d))]\n",
    "\n",
    "#     # Find the maximum sequence number within the action directory\n",
    "#     if sequence_dirs:\n",
    "#         dirmax = max(map(int, sequence_dirs))\n",
    "#     else:\n",
    "#         dirmax = 0\n",
    "\n",
    "#     # Create directories for sequences within the action directory\n",
    "#     for sequence in range(dirmax + 1, dirmax + no_sequences + 1):\n",
    "#         sequence_path = os.path.join(action_path, str(sequence))\n",
    "#         # Check if the sequence directory already exists\n",
    "#         if not os.path.exists(sequence_path):\n",
    "#             try:\n",
    "#                 os.makedirs(sequence_path)\n",
    "#             except FileExistsError:\n",
    "#                 pass\n",
    "#         else:\n",
    "#             print(f\"Sequence directory '{sequence_path}' already exists.\")\n",
    "\n",
    "\n",
    "    \n",
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join('MP_Data')\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.makedirs(DATA_PATH)\n",
    "# Actions that we try to detect (manually added first)\n",
    "actions = np.array(['hello', 'thanks'])\n",
    "\n",
    "\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 30\n",
    "\n",
    "# Videos are going to be 30 frames in length\n",
    "sequence_length = 30\n",
    "\n",
    "# Get the folders present in the MP_Data directory and sort them by creation time\n",
    "folders = sorted([folder for folder in os.listdir(DATA_PATH) if os.path.isdir(os.path.join(DATA_PATH, folder))],\n",
    "                 key=lambda folder: os.path.getctime(os.path.join(DATA_PATH, folder)))\n",
    "\n",
    "# Append the remaining actions to the actions array\n",
    "for folder in folders:\n",
    "    if folder not in actions:\n",
    "        actions = np.append(actions, folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae2f60-00dc-4765-85c9-a0979ee21700",
   "metadata": {},
   "source": [
    "# collect keypoints and landmarks for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4be203fb-2242-4f5f-a020-fbb3a40be3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_action(action):\n",
    "    action_path = os.path.join(DATA_PATH, action)\n",
    "    if not os.path.exists(action_path):\n",
    "        try:\n",
    "            os.makedirs(action_path)\n",
    "            print(f\"Action '{action}' added successfully.\")\n",
    "            # Append action to actions array\n",
    "            global actions\n",
    "            actions = np.append(actions, action)\n",
    "            record_sequences(action)\n",
    "        except FileExistsError:\n",
    "            print(f\"Action '{action}' already exists.\")\n",
    "    else:\n",
    "        print(f\"Action '{action}' already exists.\")\n",
    "        if sequences_exist(action, DATA_PATH):\n",
    "            choice = input(f\"Sequences already exist for '{action}'. Do you want to re-record them? (y/n): \")\n",
    "            if choice.lower() == 'y':\n",
    "                re_record_sequences(action)\n",
    "\n",
    "# Function to check if sequences exist for an action\n",
    "def sequences_exist(action, data_path):\n",
    "    action_path = os.path.join(data_path, action)\n",
    "    return any(os.path.isdir(os.path.join(action_path, str(i))) for i in range(no_sequences))\n",
    "# Function to re-record sequences for an action\n",
    "\n",
    "def re_record_sequences(action):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        print(f\"Re-recording sequences for {action}...\")\n",
    "        # Loop through sequences aka videos\n",
    "        for sequence in range(no_sequences):\n",
    "            print(f\"Re-recording sequence {sequence} for action {action}...\")\n",
    "            # Loop through video length aka sequence length\n",
    "            for frame_num in range(sequence_length):\n",
    "                # Read feed\n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                # Make detections\n",
    "                image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                # Draw landmarks\n",
    "                draw_styled_landmarks(image, results)\n",
    "\n",
    "                # Apply wait logic\n",
    "                if frame_num == 0: \n",
    "                    cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                    cv2.putText(image, f'Re-recording frames for {action} - Video Number {sequence}', (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "                    cv2.waitKey(1000)\n",
    "                else: \n",
    "                    cv2.putText(image, f'Re-recording frames for {action} - Video Number {sequence}', (15,12), \n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                    # Show to screen\n",
    "                    cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                # Export keypoints\n",
    "                keypoints = extract_keypoints(results)\n",
    "                npy_path = os.path.join(DATA_PATH, action, str(sequence))\n",
    "                os.makedirs(npy_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "                np.save(os.path.join(npy_path, str(frame_num) + '.npy'), keypoints)\n",
    "\n",
    "                # Break gracefully\n",
    "                if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Set mediapipe model \n",
    "def record_sequences(action):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        # Check if sequences already exist for the action\n",
    "        if not sequences_exist(action, DATA_PATH):\n",
    "            print(f\"Record sequences for {action}...\")\n",
    "            # Loop through sequences aka videos\n",
    "            for sequence in range(no_sequences):\n",
    "                print(f\"Recording sequence {sequence} for action {action}...\")\n",
    "                # Loop through video length aka sequence length\n",
    "                for frame_num in range(sequence_length):\n",
    "                    # Read feed\n",
    "                    ret, frame = cap.read()\n",
    "\n",
    "                    # Make detections\n",
    "                    image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "                    # Draw landmarks\n",
    "                    draw_styled_landmarks(image, results)\n",
    "\n",
    "                    # Apply wait logic\n",
    "                    if frame_num == 0: \n",
    "                        cv2.putText(image, 'STARTING COLLECTION', (120,200), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255, 0), 4, cv2.LINE_AA)\n",
    "                        cv2.putText(image, f'Collecting frames for {action} - Video Number {sequence}', (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "                        cv2.waitKey(1000)\n",
    "                    else: \n",
    "                        cv2.putText(image, f'Collecting frames for {action} - Video Number {sequence}', (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                        # Show to screen\n",
    "                        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                    # Export keypoints\n",
    "                    keypoints = extract_keypoints(results)\n",
    "                    npy_path = os.path.join(DATA_PATH, action, str(sequence))\n",
    "                    os.makedirs(npy_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "                    np.save(os.path.join(npy_path, str(frame_num) + '.npy'), keypoints)\n",
    "\n",
    "                    # Break gracefully\n",
    "                    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                        break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ff7195c9-fa2d-4b86-909d-e989876bbbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'hello' already exists.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sequences already exist for 'hello'. Do you want to re-record them? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'thanks' already exists.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sequences already exist for 'thanks'. Do you want to re-record them? (y/n):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'i love you' already exists.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sequences already exist for 'i love you'. Do you want to re-record them? (y/n):  n\n"
     ]
    }
   ],
   "source": [
    "add_action('hello')\n",
    "add_action('thanks')\n",
    "add_action('i love you')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cef6887f-f2e7-4543-b8d9-7ba3740f2365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'help' added successfully.\n",
      "Record sequences for help...\n",
      "Recording sequence 0 for action help...\n",
      "Recording sequence 1 for action help...\n",
      "Recording sequence 2 for action help...\n",
      "Recording sequence 3 for action help...\n",
      "Recording sequence 4 for action help...\n",
      "Recording sequence 5 for action help...\n",
      "Recording sequence 6 for action help...\n",
      "Recording sequence 7 for action help...\n",
      "Recording sequence 8 for action help...\n",
      "Recording sequence 9 for action help...\n",
      "Recording sequence 10 for action help...\n",
      "Recording sequence 11 for action help...\n",
      "Recording sequence 12 for action help...\n",
      "Recording sequence 13 for action help...\n",
      "Recording sequence 14 for action help...\n",
      "Recording sequence 15 for action help...\n",
      "Recording sequence 16 for action help...\n",
      "Recording sequence 17 for action help...\n",
      "Recording sequence 18 for action help...\n",
      "Recording sequence 19 for action help...\n",
      "Recording sequence 20 for action help...\n",
      "Recording sequence 21 for action help...\n",
      "Recording sequence 22 for action help...\n",
      "Recording sequence 23 for action help...\n",
      "Recording sequence 24 for action help...\n",
      "Recording sequence 25 for action help...\n",
      "Recording sequence 26 for action help...\n",
      "Recording sequence 27 for action help...\n",
      "Recording sequence 28 for action help...\n",
      "Recording sequence 29 for action help...\n"
     ]
    }
   ],
   "source": [
    "add_action('help')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e572058a-464b-4c3d-aa4c-cf6742504f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'fine' added successfully.\n",
      "Record sequences for fine...\n",
      "Recording sequence 0 for action fine...\n",
      "Recording sequence 1 for action fine...\n",
      "Recording sequence 2 for action fine...\n",
      "Recording sequence 3 for action fine...\n",
      "Recording sequence 4 for action fine...\n",
      "Recording sequence 5 for action fine...\n",
      "Recording sequence 6 for action fine...\n",
      "Recording sequence 7 for action fine...\n",
      "Recording sequence 8 for action fine...\n",
      "Recording sequence 9 for action fine...\n",
      "Recording sequence 10 for action fine...\n",
      "Recording sequence 11 for action fine...\n",
      "Recording sequence 12 for action fine...\n",
      "Recording sequence 13 for action fine...\n",
      "Recording sequence 14 for action fine...\n",
      "Recording sequence 15 for action fine...\n",
      "Recording sequence 16 for action fine...\n",
      "Recording sequence 17 for action fine...\n",
      "Recording sequence 18 for action fine...\n",
      "Recording sequence 19 for action fine...\n",
      "Recording sequence 20 for action fine...\n",
      "Recording sequence 21 for action fine...\n",
      "Recording sequence 22 for action fine...\n",
      "Recording sequence 23 for action fine...\n",
      "Recording sequence 24 for action fine...\n",
      "Recording sequence 25 for action fine...\n",
      "Recording sequence 26 for action fine...\n",
      "Recording sequence 27 for action fine...\n",
      "Recording sequence 28 for action fine...\n",
      "Recording sequence 29 for action fine...\n"
     ]
    }
   ],
   "source": [
    "add_action('fine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "04c494f5-7339-4ff1-8d61-20407ce2fc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'no' added successfully.\n",
      "Record sequences for no...\n",
      "Recording sequence 0 for action no...\n",
      "Recording sequence 1 for action no...\n",
      "Recording sequence 2 for action no...\n",
      "Recording sequence 3 for action no...\n",
      "Recording sequence 4 for action no...\n",
      "Recording sequence 5 for action no...\n",
      "Recording sequence 6 for action no...\n",
      "Recording sequence 7 for action no...\n",
      "Recording sequence 8 for action no...\n",
      "Recording sequence 9 for action no...\n",
      "Recording sequence 10 for action no...\n",
      "Recording sequence 11 for action no...\n",
      "Recording sequence 12 for action no...\n",
      "Recording sequence 13 for action no...\n",
      "Recording sequence 14 for action no...\n",
      "Recording sequence 15 for action no...\n",
      "Recording sequence 16 for action no...\n",
      "Recording sequence 17 for action no...\n",
      "Recording sequence 18 for action no...\n",
      "Recording sequence 19 for action no...\n",
      "Recording sequence 20 for action no...\n",
      "Recording sequence 21 for action no...\n",
      "Recording sequence 22 for action no...\n",
      "Recording sequence 23 for action no...\n",
      "Recording sequence 24 for action no...\n",
      "Recording sequence 25 for action no...\n",
      "Recording sequence 26 for action no...\n",
      "Recording sequence 27 for action no...\n",
      "Recording sequence 28 for action no...\n",
      "Recording sequence 29 for action no...\n"
     ]
    }
   ],
   "source": [
    "add_action('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e9941e31-aa38-4691-ab56-b810163d1559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'yes' already exists.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sequences already exist for 'yes'. Do you want to re-record them? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-recording sequences for yes...\n",
      "Re-recording sequence 0 for action yes...\n",
      "Re-recording sequence 1 for action yes...\n",
      "Re-recording sequence 2 for action yes...\n",
      "Re-recording sequence 3 for action yes...\n",
      "Re-recording sequence 4 for action yes...\n",
      "Re-recording sequence 5 for action yes...\n",
      "Re-recording sequence 6 for action yes...\n",
      "Re-recording sequence 7 for action yes...\n",
      "Re-recording sequence 8 for action yes...\n",
      "Re-recording sequence 9 for action yes...\n",
      "Re-recording sequence 10 for action yes...\n",
      "Re-recording sequence 11 for action yes...\n",
      "Re-recording sequence 12 for action yes...\n",
      "Re-recording sequence 13 for action yes...\n",
      "Re-recording sequence 14 for action yes...\n",
      "Re-recording sequence 15 for action yes...\n",
      "Re-recording sequence 16 for action yes...\n",
      "Re-recording sequence 17 for action yes...\n",
      "Re-recording sequence 18 for action yes...\n",
      "Re-recording sequence 19 for action yes...\n",
      "Re-recording sequence 20 for action yes...\n",
      "Re-recording sequence 21 for action yes...\n",
      "Re-recording sequence 22 for action yes...\n",
      "Re-recording sequence 23 for action yes...\n",
      "Re-recording sequence 24 for action yes...\n",
      "Re-recording sequence 25 for action yes...\n",
      "Re-recording sequence 26 for action yes...\n",
      "Re-recording sequence 27 for action yes...\n",
      "Re-recording sequence 28 for action yes...\n",
      "Re-recording sequence 29 for action yes...\n"
     ]
    }
   ],
   "source": [
    "add_action('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3c889a0-2ed5-4308-b6d6-1d96c6b98b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'phone' added successfully.\n",
      "Record sequences for phone...\n",
      "Recording sequence 0 for action phone...\n",
      "Recording sequence 1 for action phone...\n",
      "Recording sequence 2 for action phone...\n",
      "Recording sequence 3 for action phone...\n",
      "Recording sequence 4 for action phone...\n",
      "Recording sequence 5 for action phone...\n",
      "Recording sequence 6 for action phone...\n",
      "Recording sequence 7 for action phone...\n",
      "Recording sequence 8 for action phone...\n",
      "Recording sequence 9 for action phone...\n",
      "Recording sequence 10 for action phone...\n",
      "Recording sequence 11 for action phone...\n",
      "Recording sequence 12 for action phone...\n",
      "Recording sequence 13 for action phone...\n",
      "Recording sequence 14 for action phone...\n",
      "Recording sequence 15 for action phone...\n",
      "Recording sequence 16 for action phone...\n",
      "Recording sequence 17 for action phone...\n",
      "Recording sequence 18 for action phone...\n",
      "Recording sequence 19 for action phone...\n",
      "Recording sequence 20 for action phone...\n",
      "Recording sequence 21 for action phone...\n",
      "Recording sequence 22 for action phone...\n",
      "Recording sequence 23 for action phone...\n",
      "Recording sequence 24 for action phone...\n",
      "Recording sequence 25 for action phone...\n",
      "Recording sequence 26 for action phone...\n",
      "Recording sequence 27 for action phone...\n",
      "Recording sequence 28 for action phone...\n",
      "Recording sequence 29 for action phone...\n"
     ]
    }
   ],
   "source": [
    "add_action('phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d46f3eca-181e-4bfb-bcb4-0e9df9503206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'car' added successfully.\n",
      "Record sequences for car...\n",
      "Recording sequence 0 for action car...\n",
      "Recording sequence 1 for action car...\n",
      "Recording sequence 2 for action car...\n",
      "Recording sequence 3 for action car...\n",
      "Recording sequence 4 for action car...\n",
      "Recording sequence 5 for action car...\n",
      "Recording sequence 6 for action car...\n",
      "Recording sequence 7 for action car...\n",
      "Recording sequence 8 for action car...\n",
      "Recording sequence 9 for action car...\n",
      "Recording sequence 10 for action car...\n",
      "Recording sequence 11 for action car...\n",
      "Recording sequence 12 for action car...\n",
      "Recording sequence 13 for action car...\n",
      "Recording sequence 14 for action car...\n",
      "Recording sequence 15 for action car...\n",
      "Recording sequence 16 for action car...\n",
      "Recording sequence 17 for action car...\n",
      "Recording sequence 18 for action car...\n",
      "Recording sequence 19 for action car...\n",
      "Recording sequence 20 for action car...\n",
      "Recording sequence 21 for action car...\n",
      "Recording sequence 22 for action car...\n",
      "Recording sequence 23 for action car...\n",
      "Recording sequence 24 for action car...\n",
      "Recording sequence 25 for action car...\n",
      "Recording sequence 26 for action car...\n",
      "Recording sequence 27 for action car...\n",
      "Recording sequence 28 for action car...\n",
      "Recording sequence 29 for action car...\n"
     ]
    }
   ],
   "source": [
    "add_action('car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8b161ae9-a0be-4810-9932-aa0a391c6e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action 'want' added successfully.\n",
      "Record sequences for want...\n",
      "Recording sequence 0 for action want...\n",
      "Recording sequence 1 for action want...\n",
      "Recording sequence 2 for action want...\n",
      "Recording sequence 3 for action want...\n",
      "Recording sequence 4 for action want...\n",
      "Recording sequence 5 for action want...\n",
      "Recording sequence 6 for action want...\n",
      "Recording sequence 7 for action want...\n",
      "Recording sequence 8 for action want...\n",
      "Recording sequence 9 for action want...\n",
      "Recording sequence 10 for action want...\n",
      "Recording sequence 11 for action want...\n",
      "Recording sequence 12 for action want...\n",
      "Recording sequence 13 for action want...\n",
      "Recording sequence 14 for action want...\n",
      "Recording sequence 15 for action want...\n",
      "Recording sequence 16 for action want...\n",
      "Recording sequence 17 for action want...\n",
      "Recording sequence 18 for action want...\n",
      "Recording sequence 19 for action want...\n",
      "Recording sequence 20 for action want...\n",
      "Recording sequence 21 for action want...\n",
      "Recording sequence 22 for action want...\n",
      "Recording sequence 23 for action want...\n",
      "Recording sequence 24 for action want...\n",
      "Recording sequence 25 for action want...\n",
      "Recording sequence 26 for action want...\n",
      "Recording sequence 27 for action want...\n",
      "Recording sequence 28 for action want...\n",
      "Recording sequence 29 for action want...\n"
     ]
    }
   ],
   "source": [
    "add_action('want')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6ea5a113-55ee-466f-9a82-90e450e0701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_action('i love you')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a766f-f9c2-4c13-bd54-3ab49419388f",
   "metadata": {},
   "source": [
    "# preprocess data and create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e949c762-960f-4421-9ccf-79820932e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tykwo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74d81e83-8d17-48fe-a241-21f98f873ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label  in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef32a3c1-4596-49e7-93ea-2dcbea7024b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'car': 2, 'fine': 3, 'help': 4, 'no': 5, 'yes': 6}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17c06feb-d141-427a-9f32-822d20f5b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe77d5c9-4223-4d43-ae87-4469ebadaf34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'thanks': 1, 'car': 2, 'fine': 3, 'help': 4, 'no': 5, 'yes': 6}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34cfe636-b3e6-4b1a-bb13-c0bb4fe8b310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hello', 'thanks', 'car', 'fine', 'help', 'no', 'yes'], dtype='<U6')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d067d9af-302e-4c8e-bf6a-3bdecd0891ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd5d76a-f0b4-4147-942f-c7be516cf754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 30, 1662)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "777c9f65-1ab1-4a82-8662-9a195112848d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e1699ad-0d5a-46e1-878c-838fa553a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f787122-0a95-4c2e-bb1e-7001821a8f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 30, 1662)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9493da0a-6603-459a-8619-79cb174d2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(np.array(labels)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3e48b9e-02c9-48c2-adc1-f3044fb1b408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e93ca431-249d-4e15-84f7-340638a75c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee710e0e-ba31-49aa-b256-a29c2e0e00ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199, 30, 1662), (11, 30, 1662), (199, 7), (11, 7))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac4b44-a00a-4856-ba89-4351dc345ae1",
   "metadata": {},
   "source": [
    "# build and train LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e0daec4-0e5a-4345-92ce-bbf23a1a65f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f864e5bb-61fa-4f40-9603-1206ef6946eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35d540fd-109c-4ace-8157-6c900876c62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu', input_shape=(30,1662)))\n",
    "model.add(LSTM(256, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(128, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7ac2447e-f5f7-4e7a-aeab-4a26b54a2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8595bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "7/7 [==============================] - 7s 90ms/step - loss: 4.4440 - categorical_accuracy: 0.1608\n",
      "Epoch 2/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 2.5435 - categorical_accuracy: 0.1307\n",
      "Epoch 3/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.9697 - categorical_accuracy: 0.1206\n",
      "Epoch 4/500\n",
      "7/7 [==============================] - 1s 84ms/step - loss: 1.8820 - categorical_accuracy: 0.2010\n",
      "Epoch 5/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.8470 - categorical_accuracy: 0.2764\n",
      "Epoch 6/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.7414 - categorical_accuracy: 0.2915\n",
      "Epoch 7/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.7787 - categorical_accuracy: 0.2613\n",
      "Epoch 8/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.7074 - categorical_accuracy: 0.2864\n",
      "Epoch 9/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.5647 - categorical_accuracy: 0.4724\n",
      "Epoch 10/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.5907 - categorical_accuracy: 0.3467\n",
      "Epoch 11/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.6564 - categorical_accuracy: 0.2563\n",
      "Epoch 12/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 1.3884 - categorical_accuracy: 0.5176\n",
      "Epoch 13/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.8640 - categorical_accuracy: 0.5628\n",
      "Epoch 14/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 4.6185 - categorical_accuracy: 0.3367\n",
      "Epoch 15/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.8222 - categorical_accuracy: 0.1910\n",
      "Epoch 16/500\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 1.7599 - categorical_accuracy: 0.1910\n",
      "Epoch 17/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.7009 - categorical_accuracy: 0.2111\n",
      "Epoch 18/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.5975 - categorical_accuracy: 0.3719\n",
      "Epoch 19/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.4841 - categorical_accuracy: 0.4020\n",
      "Epoch 20/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.2909 - categorical_accuracy: 0.4724\n",
      "Epoch 21/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 2.1856 - categorical_accuracy: 0.4774\n",
      "Epoch 22/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.1795 - categorical_accuracy: 0.5226\n",
      "Epoch 23/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3598 - categorical_accuracy: 0.4121\n",
      "Epoch 24/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.4584 - categorical_accuracy: 0.3869\n",
      "Epoch 25/500\n",
      "7/7 [==============================] - 1s 85ms/step - loss: 1.2724 - categorical_accuracy: 0.5980\n",
      "Epoch 26/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.1682 - categorical_accuracy: 0.6734\n",
      "Epoch 27/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.2524 - categorical_accuracy: 0.6181\n",
      "Epoch 28/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.0238 - categorical_accuracy: 0.6332\n",
      "Epoch 29/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.8560 - categorical_accuracy: 0.6080\n",
      "Epoch 30/500\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 0.7778 - categorical_accuracy: 0.6231\n",
      "Epoch 31/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.7034 - categorical_accuracy: 0.6734\n",
      "Epoch 32/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6665 - categorical_accuracy: 0.6734\n",
      "Epoch 33/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 2.6378 - categorical_accuracy: 0.3015\n",
      "Epoch 34/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.8026 - categorical_accuracy: 0.2663\n",
      "Epoch 35/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.6698 - categorical_accuracy: 0.3216\n",
      "Epoch 36/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 2.1353 - categorical_accuracy: 0.2764\n",
      "Epoch 37/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.8409 - categorical_accuracy: 0.1910\n",
      "Epoch 38/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.7067 - categorical_accuracy: 0.3216\n",
      "Epoch 39/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.6516 - categorical_accuracy: 0.2663\n",
      "Epoch 40/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.6167 - categorical_accuracy: 0.3166\n",
      "Epoch 41/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.6063 - categorical_accuracy: 0.3970\n",
      "Epoch 42/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.4957 - categorical_accuracy: 0.4221\n",
      "Epoch 43/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.3277 - categorical_accuracy: 0.4523\n",
      "Epoch 44/500\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 1.4389 - categorical_accuracy: 0.4171\n",
      "Epoch 45/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 1.6471 - categorical_accuracy: 0.4422\n",
      "Epoch 46/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.6196 - categorical_accuracy: 0.4271\n",
      "Epoch 47/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.5146 - categorical_accuracy: 0.4020\n",
      "Epoch 48/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.4449 - categorical_accuracy: 0.4824\n",
      "Epoch 49/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.3053 - categorical_accuracy: 0.4673\n",
      "Epoch 50/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.1440 - categorical_accuracy: 0.5226\n",
      "Epoch 51/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 20.6478 - categorical_accuracy: 0.3668\n",
      "Epoch 52/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 4.8022 - categorical_accuracy: 0.1910\n",
      "Epoch 53/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.7659 - categorical_accuracy: 0.2915\n",
      "Epoch 54/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 1.5537 - categorical_accuracy: 0.3317\n",
      "Epoch 55/500\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 1.3814 - categorical_accuracy: 0.4975\n",
      "Epoch 56/500\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.5784 - categorical_accuracy: 0.2915\n",
      "Epoch 57/500\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 1.5341 - categorical_accuracy: 0.3166\n",
      "Epoch 58/500\n",
      "7/7 [==============================] - 1s 95ms/step - loss: 1.3399 - categorical_accuracy: 0.4673\n",
      "Epoch 59/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.3335 - categorical_accuracy: 0.4221\n",
      "Epoch 60/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 1.2930 - categorical_accuracy: 0.4623\n",
      "Epoch 61/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 1.1593 - categorical_accuracy: 0.5176\n",
      "Epoch 62/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 1.0170 - categorical_accuracy: 0.6080\n",
      "Epoch 63/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.9594 - categorical_accuracy: 0.6080\n",
      "Epoch 64/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.9873 - categorical_accuracy: 0.6080\n",
      "Epoch 65/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.9629 - categorical_accuracy: 0.5829\n",
      "Epoch 66/500\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.9021 - categorical_accuracy: 0.6231\n",
      "Epoch 67/500\n",
      "7/7 [==============================] - 1s 83ms/step - loss: 0.7950 - categorical_accuracy: 0.6683\n",
      "Epoch 68/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.8043 - categorical_accuracy: 0.6382\n",
      "Epoch 69/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6955 - categorical_accuracy: 0.7286\n",
      "Epoch 70/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 1.1385 - categorical_accuracy: 0.6935\n",
      "Epoch 71/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.9302 - categorical_accuracy: 0.6030\n",
      "Epoch 72/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.8479 - categorical_accuracy: 0.6683\n",
      "Epoch 73/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.6994 - categorical_accuracy: 0.7387\n",
      "Epoch 74/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 92ms/step - loss: 0.6005 - categorical_accuracy: 0.7990\n",
      "Epoch 75/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.7085 - categorical_accuracy: 0.6834\n",
      "Epoch 76/500\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.7213 - categorical_accuracy: 0.6884\n",
      "Epoch 77/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.6130 - categorical_accuracy: 0.7337\n",
      "Epoch 78/500\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.6018 - categorical_accuracy: 0.7286\n",
      "Epoch 79/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.6089 - categorical_accuracy: 0.7538\n",
      "Epoch 80/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.7056 - categorical_accuracy: 0.6884\n",
      "Epoch 81/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.9040 - categorical_accuracy: 0.6482\n",
      "Epoch 82/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.7552 - categorical_accuracy: 0.6533\n",
      "Epoch 83/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.7168 - categorical_accuracy: 0.7437\n",
      "Epoch 84/500\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.6561 - categorical_accuracy: 0.7889\n",
      "Epoch 85/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.5643 - categorical_accuracy: 0.7337\n",
      "Epoch 86/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.4682 - categorical_accuracy: 0.7990\n",
      "Epoch 87/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.4218 - categorical_accuracy: 0.8241\n",
      "Epoch 88/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.5167 - categorical_accuracy: 0.8392\n",
      "Epoch 89/500\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.4600 - categorical_accuracy: 0.8141\n",
      "Epoch 90/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.5491 - categorical_accuracy: 0.7387\n",
      "Epoch 91/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.5532 - categorical_accuracy: 0.7839\n",
      "Epoch 92/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.3807 - categorical_accuracy: 0.8794\n",
      "Epoch 93/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.3753 - categorical_accuracy: 0.8593\n",
      "Epoch 94/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.3269 - categorical_accuracy: 0.8693\n",
      "Epoch 95/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.2883 - categorical_accuracy: 0.8894\n",
      "Epoch 96/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.2949 - categorical_accuracy: 0.8945\n",
      "Epoch 97/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.2627 - categorical_accuracy: 0.8995\n",
      "Epoch 98/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.1953 - categorical_accuracy: 0.9246\n",
      "Epoch 99/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.1480 - categorical_accuracy: 0.9497\n",
      "Epoch 100/500\n",
      "7/7 [==============================] - 1s 94ms/step - loss: 0.1490 - categorical_accuracy: 0.9397\n",
      "Epoch 101/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.1535 - categorical_accuracy: 0.9397\n",
      "Epoch 102/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.1315 - categorical_accuracy: 0.9397\n",
      "Epoch 103/500\n",
      "7/7 [==============================] - 1s 93ms/step - loss: 0.1740 - categorical_accuracy: 0.9246\n",
      "Epoch 104/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.2857 - categorical_accuracy: 0.8995\n",
      "Epoch 105/500\n",
      "7/7 [==============================] - 1s 92ms/step - loss: 0.5512 - categorical_accuracy: 0.8291\n",
      "Epoch 106/500\n",
      "7/7 [==============================] - 1s 87ms/step - loss: 0.3543 - categorical_accuracy: 0.8543\n",
      "Epoch 107/500\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.2381 - categorical_accuracy: 0.8995\n",
      "Epoch 108/500\n",
      "7/7 [==============================] - 1s 88ms/step - loss: 0.1818 - categorical_accuracy: 0.9447\n",
      "Epoch 109/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.1817 - categorical_accuracy: 0.9447\n",
      "Epoch 110/500\n",
      "7/7 [==============================] - 1s 90ms/step - loss: 0.1772 - categorical_accuracy: 0.9497\n",
      "Epoch 111/500\n",
      "7/7 [==============================] - 1s 89ms/step - loss: 0.2843 - categorical_accuracy: 0.8844\n",
      "Epoch 112/500\n",
      "7/7 [==============================] - 1s 91ms/step - loss: 0.2560 - categorical_accuracy: 0.8995\n",
      "Epoch 113/500\n",
      "2/7 [=======>......................] - ETA: 0s - loss: 0.2151 - categorical_accuracy: 0.9219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m ):\n\u001b[0;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1325\u001b[0m     args,\n\u001b[0;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1327\u001b[0m     executing_eagerly)\n\u001b[0;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1501\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "274e2c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 30, 128)           916992    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 30, 256)           394240    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               197120    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1533575 (5.85 MB)\n",
      "Trainable params: 1533575 (5.85 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "769d3018-100a-42ed-89b8-6f31ec384ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(199, 7)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " res=model.predict(X_train)\n",
    " res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41923c0d-2708-433d-9e7c-ebb0bd42d2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fine'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(res[4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90f58ad8-0f30-4e6c-8c35-390e001bf0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[np.argmax(y_test[4])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8599772-03fe-47dd-873b-55190bd59443",
   "metadata": {},
   "source": [
    "# save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6e8f3f8d-dd8e-4914-bfb8-4588fc86f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tykwo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('actions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a616d62a-6a41-4d4b-94fb-e7f6a0d9110a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95afa5f2-fe7e-4244-a808-c6783adb1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('actions.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d93356b-2a4b-453d-92fc-a40ae227298d",
   "metadata": {},
   "source": [
    "# testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5bb42b89-58da-46ff-88b1-41e6543018f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d440608e-c3db-41e7-880f-e75ef57bef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 711ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f9ae8eb-92f5-47c2-a083-e449b1958011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.7904469e-01, 3.2584365e-05, 4.5050590e-05, 6.1489444e-02,\n",
       "        2.4712602e-02, 3.9727024e-07, 1.3467523e-01],\n",
       "       [4.7147539e-04, 1.0802801e-02, 9.8661208e-01, 2.3423365e-05,\n",
       "        1.5127372e-03, 4.6885569e-04, 1.0850248e-04],\n",
       "       [1.7388463e-01, 7.3632524e-05, 3.3271299e-05, 6.7068571e-01,\n",
       "        1.1255283e-01, 3.4977241e-08, 4.2769894e-02],\n",
       "       [2.7017727e-02, 2.8737108e-04, 6.2396307e-04, 3.9193842e-06,\n",
       "        1.0053403e-05, 9.7133315e-01, 7.2379428e-04],\n",
       "       [6.7772545e-02, 2.3762658e-04, 8.4816007e-04, 3.7665361e-06,\n",
       "        1.2120416e-05, 9.3028408e-01, 8.4159768e-04],\n",
       "       [6.7336759e-06, 3.4899701e-09, 2.7528835e-10, 7.4363960e-08,\n",
       "        3.5576175e-08, 1.8150434e-09, 9.9999309e-01],\n",
       "       [1.7658529e-05, 5.9848321e-07, 4.5601272e-08, 9.9751735e-01,\n",
       "        2.4402284e-03, 3.3014281e-14, 2.4121713e-05],\n",
       "       [2.9000817e-06, 7.3146005e-08, 4.2298853e-09, 9.9944586e-01,\n",
       "        5.4248620e-04, 3.3068047e-16, 8.6016753e-06],\n",
       "       [3.1572142e-01, 6.1667677e-05, 3.4278379e-05, 5.1494378e-01,\n",
       "        1.0093464e-01, 5.2889774e-08, 6.8304166e-02],\n",
       "       [6.0420289e-06, 7.2906274e-01, 1.1515042e-02, 1.8553272e-05,\n",
       "        2.5938907e-01, 3.8670164e-06, 4.7983544e-06],\n",
       "       [2.5810645e-04, 2.1781426e-02, 9.7519672e-01, 3.6902380e-05,\n",
       "        2.1863291e-03, 4.4672223e-04, 9.3812720e-05]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56f41f20-375d-412a-86df-8b2a3031024f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = np.argmax(y_test, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea6951fd-0e18-467d-8177-0560e3c8f8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 0, 5, 5, 6, 3, 3, 0, 1, 2]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3091120a-e3f7-4b55-a40f-f92cf4e1ac0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = np.argmax(yhat, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bf8728b6-0de6-46f6-979c-47a1924b998f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3, 5, 5, 6, 3, 3, 3, 1, 2]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a631258b-7b8f-4728-9c10-630dacc36772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8,  0],\n",
       "        [ 2,  1]],\n",
       "\n",
       "       [[10,  0],\n",
       "        [ 0,  1]],\n",
       "\n",
       "       [[ 9,  0],\n",
       "        [ 0,  2]],\n",
       "\n",
       "       [[ 7,  2],\n",
       "        [ 0,  2]],\n",
       "\n",
       "       [[ 9,  0],\n",
       "        [ 0,  2]],\n",
       "\n",
       "       [[10,  0],\n",
       "        [ 0,  1]]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c99c00a1-ee13-4e10-9889-98b3aec67b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178cb2d-02af-4d06-b98d-ece788097584",
   "metadata": {},
   "source": [
    "# test in real time (game)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a1afeb3-a91c-4a95-bde2-8b2181a8bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.rectangle(output_frame, (0,60+num*40), (int(prob*100), 90+num*40), colors[num], -1)\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5980c439-65c6-460b-98c0-b57c5167ad51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 1662)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(X_test[0],axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3ebff85b-21ca-4055-8249-a5424587a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.6757374e-17, 9.9999988e-01, 6.1893132e-08, 9.7969726e-16,\n",
       "        4.1857457e-18, 3.5896153e-16, 2.2622311e-10, 4.2731645e-11,\n",
       "        2.0033871e-08, 4.0035416e-17]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(X_test[4],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "38ae6f49-1203-41c6-bc86-563c58321061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 10)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f286b42a-ad2f-4fa1-89aa-c8048403643d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res, axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0ad8f53-41c7-41bc-adf6-5734e9b52325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ...,  True, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       [False, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[np.argmax(res, axis = -1)] > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "637db212-cb53-42e0-ae7e-f3ac305882a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. New detection variables\n",
    "# sequence = []\n",
    "# sentence = []\n",
    "# predictions = []\n",
    "# threshold = 0.5\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# # Set mediapipe model \n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     while cap.isOpened():\n",
    "\n",
    "#         # Read feed\n",
    "#         ret, frame = cap.read()\n",
    "\n",
    "#         # Make detections\n",
    "#         image, results = mediapipe_detection(frame, holistic)\n",
    "#         print(results)\n",
    "        \n",
    "#         # Draw landmarks\n",
    "#         draw_styled_landmarks(image, results)\n",
    "        \n",
    "#         # Prediction logic\n",
    "#         keypoints = extract_keypoints(results)\n",
    "#         sequence.append(keypoints)\n",
    "#         sequence = sequence[-30:]\n",
    "        \n",
    "#         if len(sequence) == 30:\n",
    "#             res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "#             print(actions[np.argmax(res)])\n",
    "#             predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "#         # Viz logic\n",
    "#             if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "#                 if res[np.argmax(res)] > threshold: \n",
    "                    \n",
    "#                     if len(sentence) > 0: \n",
    "#                         if actions[np.argmax(res)] != sentence[-1]:\n",
    "#                             sentence.append(actions[np.argmax(res)])\n",
    "#                     else:\n",
    "#                         sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "#             if len(sentence) > 5: \n",
    "#                 sentence = sentence[-5:]\n",
    "\n",
    "#         # Viz probabilities\n",
    "#         # image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "#         cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "#         cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "#                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "#         # Show to screen\n",
    "#         cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "#         # Break gracefully\n",
    "#         if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83542e1d-e9f0-4029-bc47-d46febbdadb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "hello\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "hello\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "hello\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "fine\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "fine\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "hello\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "hello\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "help\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "help\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "car\n",
      "hello\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "car\n",
      "<class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "# 1. New detection variables\n",
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.5\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model \n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        print(results)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-30:]\n",
    "        \n",
    "        if len(sequence) == 30:\n",
    "            res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "            print(actions[np.argmax(res)])\n",
    "            predictions.append(np.argmax(res))\n",
    "            \n",
    "            \n",
    "        # Viz logic\n",
    "            if np.unique(predictions[-10:])[0]==np.argmax(res): \n",
    "                for row in res:\n",
    "                    if np.max(row) > threshold:\n",
    "                        prediction = np.argmax(row)\n",
    "                        print(actions[prediction])\n",
    "                        predictions.append(prediction)\n",
    "                        sequence = []  # Reset sequence after making a prediction\n",
    "                    \n",
    "                        if len(sentence) > 0: \n",
    "                            if actions[np.argmax(res)] != sentence[-1]:\n",
    "                                sentence.append(actions[np.argmax(res)])\n",
    "                        else:\n",
    "                            sentence.append(actions[np.argmax(res)])\n",
    "\n",
    "                if len(sentence) > 5: \n",
    "                    sentence = sentence[-5:]\n",
    "\n",
    "        # Viz probabilities\n",
    "        # image = prob_viz(res, actions, image, colors)\n",
    "            \n",
    "        cv2.rectangle(image, (0,0), (640, 40), (245, 117, 16), -1)\n",
    "        cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611cc9b-df22-4e4e-89f8-de49bdeec2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10b625f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
